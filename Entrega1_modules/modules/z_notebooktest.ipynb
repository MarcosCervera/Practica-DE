{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\computation\\expressions.py:20: UserWarning: Pandas requires version '2.7.3' or newer of 'numexpr' (version '2.7.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "def api_bcra(token, endpoints):\n",
    "    df = pd.DataFrame(columns=['fecha', 'valor', 'variable'])\n",
    "    headers = {\"Authorization\": token}\n",
    "\n",
    "    for endpoint in endpoints:\n",
    "        url = \"https://api.estadisticasbcra.com/\" + endpoint\n",
    "        response = requests.get(url, headers=headers)\n",
    "        \n",
    "        # Comprobar si la solicitud fue exitosa\n",
    "        if response.status_code == 200:\n",
    "            data_json = response.json()\n",
    "            data = pd.DataFrame(data_json)\n",
    "            data = data.rename(columns={'d': 'fecha', 'v': 'valor'})\n",
    "            data['variable'] = endpoint\n",
    "            df = pd.concat([df, data], ignore_index=True)\n",
    "        else:\n",
    "            # Si hubo un error en la solicitud, imprimir el código de estado\n",
    "            print(f\"Error {response.status_code} al obtener datos del endpoint: {endpoint}\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def transform_data(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df[df[\"variable\"] != 'milestones']\n",
    "    df = df.drop(['e', 't'], axis=1)\n",
    "    df = df.pivot(index='fecha', columns='variable', values='valor')\n",
    "    df = df.reset_index()\n",
    "    df['fecha'] = pd.to_datetime(df['fecha'])\n",
    "    df2 = df[df[\"fecha\"] >= '2024-01-01']\n",
    "    return df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error 403 al obtener datos del endpoint: cajas_ahorro\n",
      "Error 403 al obtener datos del endpoint: plazo_fijo\n",
      "Error 403 al obtener datos del endpoint: cer\n",
      "Error 403 al obtener datos del endpoint: uva\n",
      "Error 403 al obtener datos del endpoint: inflacion_mensual_oficial\n",
      "Error 403 al obtener datos del endpoint: inflacion_interanual_oficial\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>variable</th>\n",
       "      <th>fecha</th>\n",
       "      <th>base</th>\n",
       "      <th>circulacion_monetaria</th>\n",
       "      <th>cuentas_corrientes</th>\n",
       "      <th>depositos</th>\n",
       "      <th>reservas</th>\n",
       "      <th>usd</th>\n",
       "      <th>usd_of</th>\n",
       "      <th>usd_of_minorista</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7038</th>\n",
       "      <td>2024-01-02</td>\n",
       "      <td>9698733.0</td>\n",
       "      <td>7463885.0</td>\n",
       "      <td>12147477.0</td>\n",
       "      <td>62846923.0</td>\n",
       "      <td>23470.0</td>\n",
       "      <td>1005.0</td>\n",
       "      <td>810.65</td>\n",
       "      <td>851.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7039</th>\n",
       "      <td>2024-01-03</td>\n",
       "      <td>9676236.0</td>\n",
       "      <td>7475870.0</td>\n",
       "      <td>12127861.0</td>\n",
       "      <td>62512714.0</td>\n",
       "      <td>23677.0</td>\n",
       "      <td>1005.0</td>\n",
       "      <td>811.15</td>\n",
       "      <td>852.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7040</th>\n",
       "      <td>2024-01-04</td>\n",
       "      <td>9692584.0</td>\n",
       "      <td>7478077.0</td>\n",
       "      <td>12155692.0</td>\n",
       "      <td>62496399.0</td>\n",
       "      <td>23835.0</td>\n",
       "      <td>1020.0</td>\n",
       "      <td>811.75</td>\n",
       "      <td>853.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7041</th>\n",
       "      <td>2024-01-05</td>\n",
       "      <td>9832701.0</td>\n",
       "      <td>7476807.0</td>\n",
       "      <td>11754373.0</td>\n",
       "      <td>62602513.0</td>\n",
       "      <td>24119.0</td>\n",
       "      <td>1025.0</td>\n",
       "      <td>812.25</td>\n",
       "      <td>852.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7042</th>\n",
       "      <td>2024-01-08</td>\n",
       "      <td>10005620.0</td>\n",
       "      <td>7469648.0</td>\n",
       "      <td>11962534.0</td>\n",
       "      <td>62054193.0</td>\n",
       "      <td>23233.0</td>\n",
       "      <td>1050.0</td>\n",
       "      <td>813.85</td>\n",
       "      <td>857.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7140</th>\n",
       "      <td>2024-06-03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1235.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7141</th>\n",
       "      <td>2024-06-04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7142</th>\n",
       "      <td>2024-06-05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1250.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7143</th>\n",
       "      <td>2024-06-06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1250.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7144</th>\n",
       "      <td>2024-06-07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>107 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "variable      fecha        base  circulacion_monetaria  cuentas_corrientes  \\\n",
       "7038     2024-01-02   9698733.0              7463885.0          12147477.0   \n",
       "7039     2024-01-03   9676236.0              7475870.0          12127861.0   \n",
       "7040     2024-01-04   9692584.0              7478077.0          12155692.0   \n",
       "7041     2024-01-05   9832701.0              7476807.0          11754373.0   \n",
       "7042     2024-01-08  10005620.0              7469648.0          11962534.0   \n",
       "...             ...         ...                    ...                 ...   \n",
       "7140     2024-06-03         NaN                    NaN                 NaN   \n",
       "7141     2024-06-04         NaN                    NaN                 NaN   \n",
       "7142     2024-06-05         NaN                    NaN                 NaN   \n",
       "7143     2024-06-06         NaN                    NaN                 NaN   \n",
       "7144     2024-06-07         NaN                    NaN                 NaN   \n",
       "\n",
       "variable   depositos  reservas     usd  usd_of  usd_of_minorista  \n",
       "7038      62846923.0   23470.0  1005.0  810.65            851.25  \n",
       "7039      62512714.0   23677.0  1005.0  811.15            852.69  \n",
       "7040      62496399.0   23835.0  1020.0  811.75            853.15  \n",
       "7041      62602513.0   24119.0  1025.0  812.25            852.99  \n",
       "7042      62054193.0   23233.0  1050.0  813.85            857.62  \n",
       "...              ...       ...     ...     ...               ...  \n",
       "7140             NaN       NaN  1235.0     NaN               NaN  \n",
       "7141             NaN       NaN  1265.0     NaN               NaN  \n",
       "7142             NaN       NaN  1250.0     NaN               NaN  \n",
       "7143             NaN       NaN  1250.0     NaN               NaN  \n",
       "7144             NaN       NaN  1265.0     NaN               NaN  \n",
       "\n",
       "[107 rows x 9 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token:str = \"BEARER eyJhbGciOiJIUzUxMiIsInR5cCI6IkpXVCJ9.eyJleHAiOjE3NDg2MTY1MzksInR5cGUiOiJleHRlcm5hbCIsInVzZXIiOiJtYXJjb3NjZXJ2ZXJhQGhvdG1haWwuY29tIn0.JU1DGL1dsqi_V4UnXBU77yu3OZpnhSvJHlEYdNnhandTewYCjbyRj-gKyixg3GkKe3ha9YMH2wFBo80t8qoGTw\"\n",
    "\n",
    "endpoints = ['milestones','usd','usd_of','usd_of_minorista','base','reservas','circulacion_monetaria',\n",
    "         'depositos','cuentas_corrientes','cajas_ahorro','plazo_fijo','cer','uva','inflacion_mensual_oficial',\n",
    "         'inflacion_interanual_oficial']\n",
    "df_bcra = api_bcra(token, endpoints)\n",
    "df_bcra = transform_data(df_bcra)\n",
    "df_bcra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an EnvironmentError: [WinError 5] Acceso denegado: 'C:\\\\ProgramData\\\\Anaconda3\\\\Lib\\\\site-packages\\\\psycopg2\\\\_psycopg.cp38-win_amd64.pyd'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: certifi==2024.2.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 1)) (2024.2.2)\n",
      "Requirement already satisfied: charset-normalizer==3.3.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 2)) (3.3.2)\n",
      "Requirement already satisfied: greenlet==3.0.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 3)) (3.0.3)\n",
      "Requirement already satisfied: idna==3.7 in c:\\programdata\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 4)) (3.7)\n",
      "Requirement already satisfied: numpy==1.24.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 5)) (1.24.4)\n",
      "Requirement already satisfied: packaging==24.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 6)) (24.0)\n",
      "Requirement already satisfied: pandas==2.0.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 7)) (2.0.3)\n",
      "Collecting psycopg2-binary==2.9.9\n",
      "  Using cached psycopg2_binary-2.9.9-cp38-cp38-win_amd64.whl (1.2 MB)\n",
      "Requirement already satisfied: python-dateutil==2.9.0.post0 in c:\\programdata\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 9)) (2.9.0.post0)\n",
      "Requirement already satisfied: python-dotenv==1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 10)) (1.0.1)\n",
      "Requirement already satisfied: pytz==2024.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 11)) (2024.1)\n",
      "Collecting requests==2.32.3\n",
      "  Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Requirement already satisfied: six==1.16.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 13)) (1.16.0)\n",
      "Collecting SQLAlchemy==1.4.52\n",
      "  Using cached SQLAlchemy-1.4.52-cp38-cp38-win_amd64.whl (1.6 MB)\n",
      "Collecting sqlalchemy-redshift==0.8.14\n",
      "  Using cached sqlalchemy_redshift-0.8.14-py2.py3-none-any.whl (38 kB)\n",
      "Collecting typing_extensions==4.12.0\n",
      "  Downloading typing_extensions-4.12.0-py3-none-any.whl (37 kB)\n",
      "Requirement already satisfied: tzdata==2024.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 17)) (2024.1)\n",
      "Collecting urllib3==2.2.1\n",
      "  Using cached urllib3-2.2.1-py3-none-any.whl (121 kB)\n",
      "Installing collected packages: psycopg2-binary, urllib3, requests, SQLAlchemy, sqlalchemy-redshift, typing-extensions\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "## conexioc Redshift\n",
    "\n",
    "import pandas as pd\n",
    "import logging\n",
    "\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "logging.basicConfig(\n",
    "    filename='app.log',\n",
    "    filemode='a',\n",
    "    format='%(asctime)s ::DataConnectionModule-> %(name)s - %(levelname)s - %(message)s',\n",
    "    level=logging.INFO)\n",
    "    \n",
    "class DataConn:\n",
    "    def __init__(self, config: dict,schema: str):\n",
    "        self.config = config\n",
    "        self.schema = schema\n",
    "        self.db_engine = None\n",
    "\n",
    "\n",
    "    def get_conn(self):\n",
    "        username = self.config.get('REDSHIFT_USERNAME')\n",
    "        password = self.config.get('REDSHIFT_PASSWORD')\n",
    "        host = self.config.get('REDSHIFT_HOST')\n",
    "        port = self.config.get('REDSHIFT_PORT', '5439')\n",
    "        dbname = self.config.get('REDSHIFT_DBNAME')\n",
    "\n",
    "        # Construct the connection URL\n",
    "        connection_url = f\"postgresql+psycopg2://{username}:{password}@{host}:{port}/{dbname}\"\n",
    "        self.db_engine = create_engine(connection_url)\n",
    "\n",
    "        try:\n",
    "            with self.db_engine.connect() as connection:\n",
    "                result = connection.execute('SELECT 1;')\n",
    "            if result:\n",
    "                logging.info(\"Connection created\")\n",
    "                return\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Failed to create connection: {e}\")\n",
    "            raise\n",
    "    \n",
    "    def check_table_exists(self, table_name:str) -> bool:\n",
    "        with self.db_engine.connect() as connection:\n",
    "            cursor = connection.cursor\n",
    "            query_checker = f\"\"\"\n",
    "                SELECT 1 FROM information_schema.tables \n",
    "                WHERE  table_schema = 'andru_ocatorres_coderhouse'\n",
    "                AND    table_name   = '{table_name}';              \n",
    "            \"\"\"\n",
    "            cursor.execute(query_checker)\n",
    "            \n",
    "            if not cursor.fetchone():\n",
    "                logging.error(f\"No {table_name} has been created\")\n",
    "                raise ValueError(f\"No {table_name} has been created\")\n",
    "\n",
    "            logging.info(f\"{table_name} exists\")\n",
    "\n",
    "    def upload_data(self, data: pd.DataFrame, table: str):\n",
    "        if self.db_engine is None:\n",
    "            logging.warning(\"Execute it before\")\n",
    "            self.get_conn()\n",
    "\n",
    "        try:\n",
    "            data.to_sql(\n",
    "                table,\n",
    "                con=self.db_engine,\n",
    "                schema=self.schema,\n",
    "                if_exists='append',\n",
    "                index=False\n",
    "            )\n",
    "\n",
    "            logging.info(f\"Data from the DataFrame has been uploaded to the {self.schema}.{table} table in Redshift.\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Failed to upload data to {self.schema}.{table}:\\n{e}\")\n",
    "            raise\n",
    "\n",
    "    def close_conn(self):\n",
    "        if self.db_engine:\n",
    "            self.db_engine.dispose()\n",
    "            logging.info(\"Connection to Redshift closed.\")\n",
    "        else:\n",
    "            logging.warning(\"No active connection to close.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to upload data to marcoscervera_coderhouse.prueba: Unable to find a usable engine; tried using: 'sqlalchemy'.\n",
      "A suitable version of sqlalchemy is required for sql I/O support.\n",
      "Trying to import the above resulted in these errors:\n",
      " - Pandas requires version '1.4.16' or newer of 'sqlalchemy' (version '1.3.20' currently installed).\n",
      "Connection to Redshift closed.\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "Unable to find a usable engine; tried using: 'sqlalchemy'.\nA suitable version of sqlalchemy is required for sql I/O support.\nTrying to import the above resulted in these errors:\n - Pandas requires version '1.4.16' or newer of 'sqlalchemy' (version '1.3.20' currently installed).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-61-520848f757c3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"__main__\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m     \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-61-520848f757c3>\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[0mdata_conn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_conn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m         \u001b[0mdata_conn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupload_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_bcra\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'prueba'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m         \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Data uploaded to -> {schema}.{table}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-60-6f7e4773d055>\u001b[0m in \u001b[0;36mupload_data\u001b[1;34m(self, data, table)\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mupload_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtable\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m             data.to_sql(\n\u001b[0m\u001b[0;32m     38\u001b[0m                 \u001b[0mtable\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m                 \u001b[0mcon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdb_engine\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mto_sql\u001b[1;34m(self, name, con, schema, if_exists, index, index_label, chunksize, dtype, method)\u001b[0m\n\u001b[0;32m   2876\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msql\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2877\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2878\u001b[1;33m         return sql.to_sql(\n\u001b[0m\u001b[0;32m   2879\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2880\u001b[0m             \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\sql.py\u001b[0m in \u001b[0;36mto_sql\u001b[1;34m(frame, name, con, schema, if_exists, index, index_label, chunksize, dtype, method, engine, **engine_kwargs)\u001b[0m\n\u001b[0;32m    767\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    768\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mpandasSQL_builder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcon\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mschema\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mneed_transaction\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpandas_sql\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 769\u001b[1;33m         return pandas_sql.to_sql(\n\u001b[0m\u001b[0;32m    770\u001b[0m             \u001b[0mframe\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    771\u001b[0m             \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\sql.py\u001b[0m in \u001b[0;36mto_sql\u001b[1;34m(self, frame, name, if_exists, index, index_label, schema, chunksize, dtype, method, engine, **engine_kwargs)\u001b[0m\n\u001b[0;32m   1906\u001b[0m             \u001b[0mAny\u001b[0m \u001b[0madditional\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0mare\u001b[0m \u001b[0mpassed\u001b[0m \u001b[0mto\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1907\u001b[0m         \"\"\"\n\u001b[1;32m-> 1908\u001b[1;33m         \u001b[0msql_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1909\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1910\u001b[0m         table = self.prep_table(\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\sql.py\u001b[0m in \u001b[0;36mget_engine\u001b[1;34m(engine)\u001b[0m\n\u001b[0;32m   1487\u001b[0m                 \u001b[0merror_msgs\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;34m\"\\n - \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1488\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1489\u001b[1;33m         raise ImportError(\n\u001b[0m\u001b[0;32m   1490\u001b[0m             \u001b[1;34m\"Unable to find a usable engine; \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1491\u001b[0m             \u001b[1;34m\"tried using: 'sqlalchemy'.\\n\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: Unable to find a usable engine; tried using: 'sqlalchemy'.\nA suitable version of sqlalchemy is required for sql I/O support.\nTrying to import the above resulted in these errors:\n - Pandas requires version '1.4.16' or newer of 'sqlalchemy' (version '1.3.20' currently installed)."
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import logging\n",
    "from dotenv import load_dotenv\n",
    "#from modules import api_bcra , transform_data , DataConn\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "def main():\n",
    "    user_credentials = {\n",
    "        \"REDSHIFT_USERNAME\" : os.getenv('REDSHIFT_USERNAME'),\n",
    "        \"REDSHIFT_PASSWORD\" : os.getenv('REDSHIFT_PASSWORD'),\n",
    "        \"REDSHIFT_HOST\" : os.getenv('REDSHIFT_HOST'),\n",
    "        \"REDSHIFT_PORT\" : os.getenv('REDSHIFT_PORT', '5439'),\n",
    "        \"REDSHIFT_DBNAME\" : os.getenv('REDSHIFT_DBNAME')\n",
    "    }\n",
    "\n",
    "    schema:str = \"marcoscervera_coderhouse\"\n",
    "    table:str = \"prueba\"\n",
    " #   token:str = \"BEARER eyJhbGciOiJIUzUxMiIsInR5cCI6IkpXVCJ9.eyJleHAiOjE3NDg3Mjg4NDEsInR5cGUiOiJleHRlcm5hbCIsInVzZXIiOiJtYXJjb3MuY2VydmVyYUBncnVwb3NhbmNyaXN0b2JhbC5jb20ifQ.7BIMFrn8dExn-Vyq8KS275NXlpn3mtOnxWnZowEGrPjBN1b-aYfgW1baMV_-1q0pLmuTmG7K4kPqHnXcZvYdZg\"\n",
    "    token:str = \"BEARER eyJhbGciOiJIUzUxMiIsInR5cCI6IkpXVCJ9.eyJleHAiOjE3NDg2MTY1MzksInR5cGUiOiJleHRlcm5hbCIsInVzZXIiOiJtYXJjb3NjZXJ2ZXJhQGhvdG1haWwuY29tIn0.JU1DGL1dsqi_V4UnXBU77yu3OZpnhSvJHlEYdNnhandTewYCjbyRj-gKyixg3GkKe3ha9YMH2wFBo80t8qoGTw\"\n",
    "\n",
    "    endpoints = ['milestones','usd','usd_of','usd_of_minorista','base','reservas','circulacion_monetaria',\n",
    "             'depositos','cuentas_corrientes','cajas_ahorro','plazo_fijo','cer','uva','inflacion_mensual_oficial',\n",
    "             'inflacion_interanual_oficial']\n",
    "\n",
    "    data_conn = DataConn(user_credentials, schema)\n",
    "#    df = api_bcra(token, endpoints)\n",
    "#    df_bcra = transform_data(df)\n",
    "    \n",
    "    try:\n",
    "        data_conn.get_conn()\n",
    "        data_conn.upload_data(df_bcra, 'prueba')\n",
    "        logging.info(f\"Data uploaded to -> {schema}.{table}\")\n",
    "\n",
    " #   except Exception as e:\n",
    " #       logging.error(f\"Not able to upload data\\n{e}\")\n",
    "        \n",
    "    finally:\n",
    "        data_conn.close_conn()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()   \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

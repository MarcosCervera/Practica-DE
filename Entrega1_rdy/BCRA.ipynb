{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pedir el token propio en la web: https://estadisticasbcra.com/api/registracion\n",
    "token = \"BEARER eyJhbGciOiJIUzUxMiIsInR5cCI6IkpXVCJ9.eyJleHAiOjE3NDg3Mjg4NDEsInR5cGUiOiJleHRlcm5hbCIsInVzZXIiOiJtYXJjb3MuY2VydmVyYUBncnVwb3NhbmNyaXN0b2JhbC5jb20ifQ.7BIMFrn8dExn-Vyq8KS275NXlpn3mtOnxWnZowEGrPjBN1b-aYfgW1baMV_-1q0pLmuTmG7K4kPqHnXcZvYdZg\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#endopint al que se llama (Ver listado de endpoins)\n",
    "ep_usd = \"usd\"\n",
    "ep_usd_of = \"usd_of\"\n",
    "#ep_usd_min = \"usd_minorista\"\n",
    "\n",
    "#datos para el llamado\n",
    "url1 = \"https://api.estadisticasbcra.com/\"+ep_usd\n",
    "url2 = \"https://api.estadisticasbcra.com/\"+ep_usd_of\n",
    "#url3 = \"https://api.estadisticasbcra.com/\"+ep_usd_min\n",
    "\n",
    "headers = {\"Authorization\": token}\n",
    "\n",
    "#Llamado\n",
    "data_json_usd = requests.get(url1, headers=headers).json()\n",
    "data_json_usd_of = requests.get(url2, headers=headers).json()\n",
    "#data_json_usd_min = requests.get(url3, headers=headers).json()\n",
    "\n",
    "#Armamos una tabla con los datos\n",
    "bd_usd = pd.DataFrame(data_json_usd)\n",
    "bd_usd_of = pd.DataFrame(data_json_usd_of)\n",
    "#bd_usd_min = pd.DataFrame(data_json_usd_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cambia nombre de columnas\n",
    "bd_usd = bd_usd.rename(columns={'d':'Fecha' , 'v':'usd' })\n",
    "bd_usd_of = bd_usd_of.rename(columns={'d':'Fecha' , 'v':'usd_of' })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fecha</th>\n",
       "      <th>usd</th>\n",
       "      <th>usd_of</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000-05-24</td>\n",
       "      <td>1.0005</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000-05-25</td>\n",
       "      <td>1.0005</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000-05-26</td>\n",
       "      <td>1.0004</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000-05-29</td>\n",
       "      <td>1.0007</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000-05-30</td>\n",
       "      <td>1.0009</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6007</th>\n",
       "      <td>2024-05-24</td>\n",
       "      <td>1220.0000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6008</th>\n",
       "      <td>2024-05-27</td>\n",
       "      <td>1205.0000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6009</th>\n",
       "      <td>2024-05-28</td>\n",
       "      <td>1210.0000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6010</th>\n",
       "      <td>2024-05-29</td>\n",
       "      <td>1230.0000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6011</th>\n",
       "      <td>2024-05-30</td>\n",
       "      <td>1230.0000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6012 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Fecha        usd  usd_of\n",
       "0     2000-05-24     1.0005     NaN\n",
       "1     2000-05-25     1.0005     NaN\n",
       "2     2000-05-26     1.0004     NaN\n",
       "3     2000-05-29     1.0007     NaN\n",
       "4     2000-05-30     1.0009     NaN\n",
       "...          ...        ...     ...\n",
       "6007  2024-05-24  1220.0000     NaN\n",
       "6008  2024-05-27  1205.0000     NaN\n",
       "6009  2024-05-28  1210.0000     NaN\n",
       "6010  2024-05-29  1230.0000     NaN\n",
       "6011  2024-05-30  1230.0000     NaN\n",
       "\n",
       "[6012 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Junta tablas\n",
    "bd_bcra = pd.merge(bd_usd, bd_usd_of , on='Fecha',  how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting beautifulsoup4==4.12.3\n",
      "  Using cached beautifulsoup4-4.12.3-py3-none-any.whl (147 kB)\n",
      "Collecting certifi==2024.2.2\n",
      "  Using cached certifi-2024.2.2-py3-none-any.whl (163 kB)\n",
      "Collecting charset-normalizer==3.3.2\n",
      "  Using cached charset_normalizer-3.3.2-cp38-cp38-win_amd64.whl (99 kB)\n",
      "Collecting frozendict==2.4.4\n",
      "  Using cached frozendict-2.4.4-cp38-cp38-win_amd64.whl (37 kB)\n",
      "Collecting greenlet==3.0.3\n",
      "  Using cached greenlet-3.0.3-cp38-cp38-win_amd64.whl (290 kB)\n",
      "Requirement already satisfied: html5lib==1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 6)) (1.1)\n",
      "Collecting idna==3.7\n",
      "  Using cached idna-3.7-py3-none-any.whl (66 kB)\n",
      "Collecting lxml==5.2.2\n",
      "  Using cached lxml-5.2.2-cp38-cp38-win_amd64.whl (3.8 MB)\n",
      "Collecting multitasking==0.0.11\n",
      "  Using cached multitasking-0.0.11-py3-none-any.whl (8.5 kB)\n",
      "Collecting numpy==1.24.4\n",
      "  Downloading numpy-1.24.4-cp38-cp38-win_amd64.whl (14.9 MB)\n",
      "Collecting packaging==24.0\n",
      "  Using cached packaging-24.0-py3-none-any.whl (53 kB)\n",
      "Collecting pandas==2.0.3\n",
      "  Downloading pandas-2.0.3-cp38-cp38-win_amd64.whl (10.8 MB)\n",
      "Collecting peewee==3.17.5\n",
      "  Downloading peewee-3.17.5.tar.gz (3.0 MB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "    Preparing wheel metadata: started\n",
      "    Preparing wheel metadata: finished with status 'done'\n",
      "Collecting platformdirs==4.2.2\n",
      "  Downloading platformdirs-4.2.2-py3-none-any.whl (18 kB)\n",
      "Collecting psycopg-binary==3.1.19\n",
      "  Downloading psycopg_binary-3.1.19-cp38-cp38-win_amd64.whl (2.9 MB)\n",
      "Collecting psycopg2-binary==2.9.9\n",
      "  Downloading psycopg2_binary-2.9.9-cp38-cp38-win_amd64.whl (1.2 MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an EnvironmentError: [WinError 5] Acceso denegado: 'C:\\\\ProgramData\\\\Anaconda3\\\\Lib\\\\site-packages\\\\~-mpy\\\\.libs\\\\libopenblas.WCDJNK7YVMPZQ2ME2ZZHJJRJ3JIKNDB7.gfortran-win_amd64.dll'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-dateutil==2.9.0.post0\n",
      "  Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
      "Collecting python-dotenv==1.0.1\n",
      "  Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Collecting pytz==2024.1\n",
      "  Downloading pytz-2024.1-py2.py3-none-any.whl (505 kB)\n",
      "Collecting requests==2.32.2\n",
      "  Downloading requests-2.32.2-py3-none-any.whl (63 kB)\n",
      "Collecting six==1.16.0\n",
      "  Downloading six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
      "Collecting soupsieve==2.5\n",
      "  Downloading soupsieve-2.5-py3-none-any.whl (36 kB)\n",
      "Collecting SQLAlchemy==1.4.52\n",
      "  Downloading SQLAlchemy-1.4.52-cp38-cp38-win_amd64.whl (1.6 MB)\n",
      "Collecting sqlalchemy-redshift==0.8.14\n",
      "  Downloading sqlalchemy_redshift-0.8.14-py2.py3-none-any.whl (38 kB)\n",
      "Collecting tzdata==2024.1\n",
      "  Downloading tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n",
      "Collecting urllib3==2.2.1\n",
      "  Downloading urllib3-2.2.1-py3-none-any.whl (121 kB)\n",
      "Requirement already satisfied: webencodings==0.5.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 27)) (0.5.1)\n",
      "Building wheels for collected packages: peewee\n",
      "  Building wheel for peewee (PEP 517): started\n",
      "  Building wheel for peewee (PEP 517): finished with status 'done'\n",
      "  Created wheel for peewee: filename=peewee-3.17.5-py3-none-any.whl size=138681 sha256=34f00bb21f8cccc5cb30f772f8de8791d547e54e6ed7e77828291d10e0b02896\n",
      "  Stored in directory: c:\\users\\cerveram\\appdata\\local\\pip\\cache\\wheels\\50\\f5\\5d\\c6bc991ef2e027c2d14113be120f99704e268b48057a90529d\n",
      "Successfully built peewee\n",
      "Installing collected packages: soupsieve, beautifulsoup4, certifi, charset-normalizer, frozendict, greenlet, idna, lxml, multitasking, numpy, packaging, tzdata, six, python-dateutil, pytz, pandas, peewee, platformdirs, psycopg-binary, psycopg2-binary, python-dotenv, urllib3, requests, SQLAlchemy, sqlalchemy-redshift\n",
      "  Attempting uninstall: soupsieve\n",
      "    Found existing installation: soupsieve 2.0.1\n",
      "    Uninstalling soupsieve-2.0.1:\n",
      "      Successfully uninstalled soupsieve-2.0.1\n",
      "  Attempting uninstall: beautifulsoup4\n",
      "    Found existing installation: beautifulsoup4 4.9.1\n",
      "    Uninstalling beautifulsoup4-4.9.1:\n",
      "      Successfully uninstalled beautifulsoup4-4.9.1\n",
      "  Attempting uninstall: certifi\n",
      "    Found existing installation: certifi 2020.6.20\n",
      "    Uninstalling certifi-2020.6.20:\n",
      "      Successfully uninstalled certifi-2020.6.20\n",
      "  Attempting uninstall: greenlet\n",
      "    Found existing installation: greenlet 0.4.17\n",
      "    Uninstalling greenlet-0.4.17:\n",
      "      Successfully uninstalled greenlet-0.4.17\n",
      "  Attempting uninstall: idna\n",
      "    Found existing installation: idna 2.10\n",
      "    Uninstalling idna-2.10:\n",
      "      Successfully uninstalled idna-2.10\n",
      "  Attempting uninstall: lxml\n",
      "    Found existing installation: lxml 4.6.1\n",
      "    Uninstalling lxml-4.6.1:\n",
      "      Successfully uninstalled lxml-4.6.1\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.19.5\n",
      "    Uninstalling numpy-1.19.5:\n",
      "      Successfully uninstalled numpy-1.19.5\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crea conexiÃ³n\n",
    "import pandas as pd\n",
    "\n",
    "from io import StringIO\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "    \n",
    "class DataConn:\n",
    "    def __init__(self, config: dict,schema: str):\n",
    "        self.config = config\n",
    "        self.schema = schema\n",
    "        self.db_engine = None\n",
    "\n",
    "\n",
    "    def get_conn(self):\n",
    "        username = self.config.get('REDSHIFT_USERNAME')\n",
    "        password = self.config.get('REDSHIFT_PASSWORD')\n",
    "        host = self.config.get('REDSHIFT_HOST')\n",
    "        port = self.config.get('REDSHIFT_PORT', '5439')\n",
    "        dbname = self.config.get('REDSHIFT_DBNAME')\n",
    "\n",
    "        # Construct the connection URL\n",
    "        connection_url = f\"postgresql+psycopg2://{username}:{password}@{host}:{port}/{dbname}\"\n",
    "        self.db_engine = create_engine(connection_url)\n",
    "\n",
    "        try:\n",
    "            with self.db_engine.connect() as connection:\n",
    "                result = connection.execute('SELECT 1;')\n",
    "            if result:\n",
    "                return\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to create connection: {e}\")\n",
    "            raise\n",
    "\n",
    "    def upload_data(self, data: pd.DataFrame, table: str):\n",
    "        try:\n",
    "            data.to_sql(\n",
    "                table,\n",
    "                con=self.db_engine,\n",
    "                schema=self.schema,\n",
    "                if_exists='append',\n",
    "                index=False\n",
    "            )\n",
    "\n",
    "            print(f\"Data from the DataFrame has been uploaded to the {self.schema}.{table} table in Redshift.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to upload data to {self.schema}.{table}: {e}\")\n",
    "            raise\n",
    "\n",
    "    def close_conn(self):\n",
    "        if self.db_engine:\n",
    "            self.db_engine.dispose()\n",
    "            print(\"Connection to Redshift closed.\")\n",
    "        else:\n",
    "            print(\"No active connection to close.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-dotenv\n",
      "  Using cached python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Installing collected packages: python-dotenv\n",
      "Successfully installed python-dotenv-1.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install python-dotenv\n",
    "!pip install psycopg2\n",
    "#import dotenv\n",
    "#import psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Fecha     usd  usd_of\n",
      "0  2000-05-24  1.0005     NaN\n",
      "1  2000-05-25  1.0005     NaN\n",
      "2  2000-05-26  1.0004     NaN\n",
      "3  2000-05-29  1.0007     NaN\n",
      "4  2000-05-30  1.0009     NaN\n",
      "Data from the DataFrame has been uploaded to the marcoscervera_coderhouse.stage_bcra table in Redshift.\n",
      "Connection to Redshift closed.\n"
     ]
    }
   ],
   "source": [
    "# Carga tabla\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "user_credentials = {\n",
    "    \"REDSHIFT_USERNAME\" : os.getenv('REDSHIFT_USERNAME'),\n",
    "    \"REDSHIFT_PASSWORD\" : os.getenv('REDSHIFT_PASSWORD'),\n",
    "    \"REDSHIFT_HOST\" : os.getenv('REDSHIFT_HOST'),\n",
    "    \"REDSHIFT_PORT\" : os.getenv('REDSHIFT_PORT', '5439'),\n",
    "    \"REDSHIFT_DBNAME\" : os.getenv('REDSHIFT_DBNAME')\n",
    "}\n",
    "\n",
    "schema = \"marcoscervera_coderhouse\"\n",
    "data_conn = DataConn(user_credentials, schema)\n",
    "\n",
    "\n",
    "try:\n",
    "    data_conn.get_conn()\n",
    "    print(bd_bcra.head())\n",
    "    data_conn.upload_data(bd_bcra, 'stage_bcra')\n",
    "finally:\n",
    "    data_conn.close_conn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
